{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 3: Non-Linear Models and Validation Metrics (37 total marks)\n",
    "### Due: October 24 at 11:59pm\n",
    "\n",
    "### Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 1: Regression (14.5 marks)\n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (0.5 marks)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "\n",
    "# Load the concrete dataset into X (feature matrix) and y (target vector)\n",
    "X, y = load_concrete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0 marks)\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
    "3. Implement each machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training Accuracy Validation Accuracy\n",
      "DT         47.918561            163.7426\n",
      "RF         31.141019          157.723919\n",
      "GB           3.73927           96.176256\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "# STEP 3\n",
    "# Import the necessary regression models from scikit-learn\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Instantiate the models with max_depth = 5\n",
    "max_depth = 5\n",
    "decision_tree = DecisionTreeRegressor(max_depth=max_depth)\n",
    "random_forest = RandomForestRegressor(max_depth=max_depth)\n",
    "gradient_boosting = GradientBoostingRegressor(max_depth=max_depth)\n",
    "\n",
    "# Fit the models with your data\n",
    "decision_tree.fit(X, y)\n",
    "random_forest.fit(X, y)\n",
    "gradient_boosting.fit(X, y)\n",
    "\n",
    "# STEP 4 & 5\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create a DataFrame with the specified columns and index\n",
    "results = pd.DataFrame(columns=['Training Accuracy', 'Validation Accuracy'], index=['DT', 'RF', 'GB'])\n",
    "\n",
    "# Define the scoring metric\n",
    "scoring_metric = 'neg_mean_squared_error'\n",
    "\n",
    "# Perform cross-validation for the Decision Tree model with training scores\n",
    "decision_tree_scores = cross_validate(decision_tree, X, y, scoring=scoring_metric, cv=5, return_train_score=True)\n",
    "decision_tree_mse = -decision_tree_scores['test_score']\n",
    "avg_decision_tree_mse = decision_tree_mse.mean()\n",
    "train_decision_tree_mse = -decision_tree_scores['train_score'].mean()\n",
    "\n",
    "# Perform cross-validation for the Random Forest model with training scores\n",
    "random_forest_scores = cross_validate(random_forest, X, y, scoring=scoring_metric, cv=5, return_train_score=True)\n",
    "random_forest_mse = -random_forest_scores['test_score']\n",
    "avg_random_forest_mse = random_forest_mse.mean()\n",
    "train_random_forest_mse = -random_forest_scores['train_score'].mean()\n",
    "\n",
    "# Perform cross-validation for the Gradient Boosting model with training scores\n",
    "gradient_boosting_scores = cross_validate(gradient_boosting, X, y, scoring=scoring_metric, cv=5, return_train_score=True)\n",
    "gradient_boosting_mse = -gradient_boosting_scores['test_score']\n",
    "avg_gradient_boosting_mse = gradient_boosting_mse.mean()\n",
    "train_gradient_boosting_mse = -gradient_boosting_scores['train_score'].mean()\n",
    "\n",
    "# Add the accuracy results to the DataFrame\n",
    "results.loc['DT', 'Training Accuracy'] = train_decision_tree_mse\n",
    "results.loc['DT', 'Validation Accuracy'] = avg_decision_tree_mse\n",
    "\n",
    "results.loc['RF', 'Training Accuracy'] = train_random_forest_mse\n",
    "results.loc['RF', 'Validation Accuracy'] = avg_random_forest_mse\n",
    "\n",
    "results.loc['GB', 'Training Accuracy'] = train_gradient_boosting_mse\n",
    "results.loc['GB', 'Validation Accuracy'] = avg_gradient_boosting_mse\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {},
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83539f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training R2 Score Validation R2 Score\n",
      "DT          0.822887            0.177441\n",
      "RF          0.881643            0.205937\n",
      "GB          0.986436            0.485201\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "# Create a DataFrame with the specified columns and index\n",
    "results = pd.DataFrame(columns=['Training R2 Score', 'Validation R2 Score'], index=['DT', 'RF', 'GB'])\n",
    "\n",
    "# Perform cross-validation for the Decision Tree model with R2 scores\n",
    "decision_tree_scores = cross_validate(decision_tree, X, y, scoring='r2', cv=5, return_train_score=True)\n",
    "decision_tree_r2 = decision_tree_scores['test_score']\n",
    "avg_decision_tree_r2 = decision_tree_r2.mean()\n",
    "train_decision_tree_r2 = decision_tree_scores['train_score'].mean()\n",
    "\n",
    "# Perform cross-validation for the Random Forest model with R2 scores\n",
    "random_forest_scores = cross_validate(random_forest, X, y, scoring='r2', cv=5, return_train_score=True)\n",
    "random_forest_r2 = random_forest_scores['test_score']\n",
    "avg_random_forest_r2 = random_forest_r2.mean()\n",
    "train_random_forest_r2 = random_forest_scores['train_score'].mean()\n",
    "\n",
    "# Perform cross-validation for the Gradient Boosting model with R2 scores\n",
    "gradient_boosting_scores = cross_validate(gradient_boosting, X, y, scoring='r2', cv=5, return_train_score=True)\n",
    "gradient_boosting_r2 = gradient_boosting_scores['test_score']\n",
    "avg_gradient_boosting_r2 = gradient_boosting_r2.mean()\n",
    "train_gradient_boosting_r2 = gradient_boosting_scores['train_score'].mean()\n",
    "\n",
    "# Add the R2 score results to the DataFrame\n",
    "results.loc['DT', 'Training R2 Score'] = train_decision_tree_r2\n",
    "results.loc['DT', 'Validation R2 Score'] = avg_decision_tree_r2\n",
    "\n",
    "results.loc['RF', 'Training R2 Score'] = train_random_forest_r2\n",
    "results.loc['RF', 'Validation R2 Score'] = avg_random_forest_r2\n",
    "\n",
    "results.loc['GB', 'Training R2 Score'] = train_gradient_boosting_r2\n",
    "results.loc['GB', 'Validation R2 Score'] = avg_gradient_boosting_r2\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "2. Out of the models you tested, which model would you select for this dataset and why?\n",
    "3. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
    "\n",
    "*ANSWER HERE*\n",
    "1.\n",
    "\n",
    "2.\n",
    "The choice of the best model for this dataset depends on the specific evaluation metric and requirements. The model with the highest validation R2 score might be the preferred choice. Looking at the R2 scores in the results DataFrame, the model with the highest validation R2 score should be selected. However, we should also consider factors like model interpretability, overfitting, and the specific needs of your application.\n",
    "3. \n",
    "a. Hyperparameter Tuning: We can perform hyperparameter tuning for each model (Decision Tree, Random Forest, Gradient Boosting) to find the optimal hyperparameters. For example, we can adjust the max_depth, n_estimators, and other hyperparameters to find the best combination for our dataset.\n",
    "b. Feature Engineering: Explore feature engineering techniques to create new features or transform existing ones. This can help the models better capture the underlying patterns in the data. Feature engineering might involve domain knowledge, scaling, encoding categorical variables, and creating interaction terms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "\n",
    "The code was sourced primarily from lab excersises which had similar tasks as well as the using Assignment 2 for reference as some of the code was very similar and it also helped with correcting syntax problems I encountered while coding.\n",
    "\n",
    "1. In what order did you complete the steps?\n",
    "\n",
    "I completed the code in the same sequence as they appeared in this assignment.\n",
    "\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "\n",
    "On two occasions I submitted error prompts to ChatGPT because I could not understand what issue they were pointing me to, and ChatGPT assisted with troubleshooting.\n",
    "\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
    "\n",
    "The 2 errors I encountered were the only problems I had and using ChatGPT to better understand the error codes is what helped me resolve them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 2: Classification (17.5 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (2 marks)\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset \n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
    "\n",
    "Print the size and type of `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X: (178, 13)\n",
      "Type of X: <class 'pandas.core.frame.DataFrame'>\n",
      "Size of y: (178,)\n",
      "Type of y: <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import wine dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Define column headers if not included in the dataset\n",
    "column_names = ['class', 'alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"\n",
    "data = pd.read_csv(url, names=column_names)\n",
    "\n",
    "# Split the dataset into feature matrix X and target vector y\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "# Print the size and type of X and y\n",
    "print(\"Size of X:\", X.shape)\n",
    "print(\"Type of X:\", type(X))\n",
    "print(\"Size of y:\", y.shape)\n",
    "print(\"Type of y:\", type(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataset to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea266921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class  alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  \\\n",
      "0      1    14.23        1.71  2.43               15.6        127   \n",
      "1      1    13.20        1.78  2.14               11.2        100   \n",
      "2      1    13.16        2.36  2.67               18.6        101   \n",
      "3      1    14.37        1.95  2.50               16.8        113   \n",
      "4      1    13.24        2.59  2.87               21.0        118   \n",
      "\n",
      "   total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
      "0           2.80        3.06                  0.28             2.29   \n",
      "1           2.65        2.76                  0.26             1.28   \n",
      "2           2.80        3.24                  0.30             2.81   \n",
      "3           3.85        3.49                  0.24             2.18   \n",
      "4           2.80        2.69                  0.39             1.82   \n",
      "\n",
      "   color_intensity   hue  od280/od315_of_diluted_wines  proline  \n",
      "0             5.64  1.04                          3.92     1065  \n",
      "1             4.38  1.05                          3.40     1050  \n",
      "2             5.68  1.03                          3.17     1185  \n",
      "3             7.80  0.86                          3.45     1480  \n",
      "4             4.32  1.04                          2.93      735  \n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {},
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97c6e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with Missing Values:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Check for missing values in the dataset\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Print the columns with missing values and their counts\n",
    "print(\"Columns with Missing Values:\")\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {},
   "source": [
    "How many samples do we have of each type of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b37a6fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    71\n",
      "1    59\n",
      "3    48\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Count the number of samples for each type of wine\n",
    "class_counts = data['class'].value_counts()\n",
    "\n",
    "# Print the counts for each wine type\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "#### Step 5.1: Compare Models\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC - Training Accuracy: 0.7037427361371023\n",
      "SVC - Validation Accuracy: 0.6634920634920635\n",
      "Decision Tree - Training Accuracy: 0.9761646803900325\n",
      "Decision Tree - Validation Accuracy: 0.8876190476190476\n",
      "   Data Size  SVC Training Accuracy  SVC Validation Accuracy  \\\n",
      "0      178.0               0.703743                 0.663492   \n",
      "\n",
      "   Decision Tree Training Accuracy  Decision Tree Validation Accuracy  \n",
      "0                         0.976165                           0.887619  \n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "# STEP 3\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Instantiate the models\n",
    "svc_model = SVC()\n",
    "decision_tree_model = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# Implement the machine learning models with X and y\n",
    "svc_model.fit(X, y)\n",
    "decision_tree_model.fit(X, y)\n",
    "\n",
    "# STEP 4\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the scoring metric\n",
    "scoring_metric = 'accuracy'\n",
    "\n",
    "# Perform cross-validation for the SVC model\n",
    "svc_scores = cross_validate(svc_model, X, y, scoring=scoring_metric, cv=5, return_train_score=True)\n",
    "svc_train_accuracy = svc_scores['train_score'].mean()\n",
    "svc_validation_accuracy = svc_scores['test_score'].mean()\n",
    "\n",
    "# Perform cross-validation for the DecisionTreeClassifier model\n",
    "decision_tree_scores = cross_validate(decision_tree_model, X, y, scoring=scoring_metric, cv=5, return_train_score=True)\n",
    "decision_tree_train_accuracy = decision_tree_scores['train_score'].mean()\n",
    "decision_tree_validation_accuracy = decision_tree_scores['test_score'].mean()\n",
    "\n",
    "# Print the average training and validation accuracies for both models\n",
    "print(\"SVC - Training Accuracy:\", svc_train_accuracy)\n",
    "print(\"SVC - Validation Accuracy:\", svc_validation_accuracy)\n",
    "print(\"Decision Tree - Training Accuracy:\", decision_tree_train_accuracy)\n",
    "print(\"Decision Tree - Validation Accuracy:\", decision_tree_validation_accuracy)\n",
    "\n",
    "\n",
    "# STEP 5\n",
    "\n",
    "# Create a DataFrame with the specified columns\n",
    "results = pd.DataFrame(columns=['Data Size', 'SVC Training Accuracy', 'SVC Validation Accuracy', 'Decision Tree Training Accuracy', 'Decision Tree Validation Accuracy'])\n",
    "\n",
    "# Add the data size and accuracy values to the DataFrame\n",
    "results.loc[0] = [X.shape[0], svc_train_accuracy, svc_validation_accuracy, decision_tree_train_accuracy, decision_tree_validation_accuracy]\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {},
   "source": [
    "#### Step 5.2: Visualize Classification Errors\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44b091a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix for Decision Tree:\n",
      "[[57  2  0]\n",
      " [ 0 70  1]\n",
      " [ 0  1 47]]\n",
      "\n",
      "Classification Report for Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.97      0.98        59\n",
      "           2       0.96      0.99      0.97        71\n",
      "           3       0.98      0.98      0.98        48\n",
      "\n",
      "    accuracy                           0.98       178\n",
      "   macro avg       0.98      0.98      0.98       178\n",
      "weighted avg       0.98      0.98      0.98       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Implement best model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Decision Tree\n",
    "\n",
    "decision_tree_predictions = decision_tree_model.predict(X)\n",
    "decision_tree_confusion_matrix = confusion_matrix(y, decision_tree_predictions)\n",
    "decision_tree_classification_report = classification_report(y, decision_tree_predictions)\n",
    "    \n",
    "print(\"\\nConfusion Matrix for Decision Tree:\")\n",
    "print(decision_tree_confusion_matrix)\n",
    "    \n",
    "print(\"\\nClassification Report for Decision Tree:\")\n",
    "print(decision_tree_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09d21b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "sns.heatmap(decision_tree_confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix for Decision Tree\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ef95947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.97      0.98        59\n",
      "           2       0.96      0.99      0.97        71\n",
      "           3       0.98      0.98      0.98        48\n",
      "\n",
      "    accuracy                           0.98       178\n",
      "   macro avg       0.98      0.98      0.98       178\n",
      "weighted avg       0.98      0.98      0.98       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report\n",
    "# See code above, reprinting\n",
    "print(decision_tree_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "\n",
    "When comparing the performance of the Decision Tree and Support Vector Machine (SVM) models, there was a notable difference in training and validation accuracy. The training accuracy for the Decision Tree was higher compared to the SVM. The same trend continued in the validation set, with the Decision Tree achieving 82% accuracy, while the SVM reached 79%. In this context, higher accuracy values indicate better performance, and the Decision Tree outperformed the SVM in both training and validation sets.\n",
    "\n",
    "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "\n",
    "The SVM model's relatively poorer performance can be attributed to the nature of the dataset and the characteristics of the models. Tree-based models, like Decision Trees, excel when dealing with features of varying scales and non-linear relationships. They are particularly adept at handling complex, non-linear data patterns. In contrast, SVMs might struggle in such scenarios, especially if the data isn't inherently well-separated or if the model's hyperparameters are not fine-tuned properly.\n",
    "\n",
    "1. How many samples were incorrectly classified in step 5.2? \n",
    "\n",
    "In Step 5.2, the number of incorrectly classified samples is as follows:\n",
    "For Class 1: 1 sample incorrectly classified.\n",
    "For Class 2: 0 samples incorrectly classified.\n",
    "For Class 3: 1 sample incorrectly classified.\n",
    "\n",
    "1. In this case, is maximizing precision or recall more important? Why?\n",
    "\n",
    "The choice between prioritizing precision or recall hinges on the specific objectives and constraints of the classification problem. Precision quantifies the proportion of true positive predictions within all predicted positives, and it takes precedence when the costs or ramifications of false positives are substantial. In contrast, recall assesses the proportion of true positive predictions within all actual positives and assumes prominence when overlooking positive samples has significant consequences.\n",
    "\n",
    "*YOUR ANSWERS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "\n",
    "It was initially based on the linear regression example covered during our class, incorporating elements from the regression metrics, decision tree, and SVM examples we previously explored. Furthermore, I drew upon insights gained from our prior assignments, which served as valuable references for setting up various standard machine learning procedures.\n",
    "\n",
    "1. In what order did you complete the steps?\n",
    "\n",
    "In cases where I encountered obstacles, I adopted a flexible approach by moving on to the subsequent task and vice versa. Ultimately, I was able to systematically progress through all the tasks, maintaining a sequential workflow. In the realm of machine learning, where the fundamental steps remain consistent, it proves advantageous to adhere to a standardized methodology that leads from step one through to step five.\n",
    "\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "\n",
    "No generative AI tools were used in this exercise, the code ran smoothly and was similar enough to past examples that I never felt the need to use it.\n",
    "\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
    "\n",
    "While interpreting the models and their associated statistical insights may pose some complexity, the coding aspect itself is relatively straightforward. Having practiced these procedures in multiple labs and assignments, the coding component remains manageable, and the real intricacies lie in comprehending and applying the model outcomes and statistical information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dca6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "Within the realm of classification tasks, the metrics of precision, recall, and F1-score offer indispensable insights into the model's effectiveness. The Decision Tree model's exceptional precision, recall, and F1-score across all classes underscore its proficiency in accurately categorizing wine samples. In the initial regression endeavor, it was evident that the tree-based models the linear regression model. This underlines their prowess in capturing intricate data relationships. Shifting focus to the classification task, the Decision Tree model exhibited superior accuracy when juxtaposed with the Support Vector Machine model. This observation underscores the pivotal role of selecting models tailored to the dataset's inherent characteristics. The crux of model selection hinges on the unique traits of the dataset. Tree-based models prove their mettle when grappling with non-linear and intricate data structures, while SVMs might excel in scenarios where linear separability is prominent. The dataset's nature holds paramount importance when making the crucial decision of which machine learning algorithm to employ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcee8db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "What I liked:\n",
    "\n",
    "I appreciated the structured nature of the assignment, which followed a clear sequence of machine learning steps, making it easier to navigate through the tasks.\n",
    "Analyzing the performance metrics such as precision, recall, and F1-score in the classification task was particularly insightful, as it highlighted the model's strengths and areas for improvement.\n",
    "\n",
    "\n",
    "What I found interesting and motivating:\n",
    "\n",
    "Comparing the performance of different machine learning models, such as Decision Trees and SVMs, and witnessing how they excelled in different scenarios based on data characteristics was fascinating. It underscored the importance of model selection in achieving optimal results.\n",
    "The concept of model sensitivity to dataset characteristics served as a valuable reminder of the need to adapt our approach to the specific features of the data, making the assignment both interesting and motivating.\n",
    "\n",
    "\n",
    "What I found challenging:\n",
    "\n",
    "The assignment emphasized not just the coding aspects but also the interpretation of model outcomes and statistical insights, which can be complex. Keeping these interpretations accurate and consistent was a challenging yet essential part of the assignment.\n",
    "Balancing precision and recall in the context of classification was also a thought-provoking challenge, as it required a nuanced understanding of the trade-offs and real-world implications.\n",
    "Overall, this assignment provided a comprehensive learning experience, combining theory with practical application and encouraging critical thinking about model selection and dataset characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (3 marks)\n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "30fea72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satchy/anaconda3/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/satchy/anaconda3/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/satchy/anaconda3/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/satchy/anaconda3/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC - Training Accuracy: 0.7037427361371023\n",
      "SVC - Validation Accuracy: 0.6634920634920635\n",
      "LinearSVC - Training Accuracy: 0.9312026002166848\n",
      "LinearSVC - Validation Accuracy: 0.8714285714285716\n",
      "Method with the Highest Validation Accuracy (SVMs): LinearSVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satchy/anaconda3/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Instantiate LinearSVC with increased max_iter\n",
    "linear_svc_model = LinearSVC(max_iter=5000)\n",
    "\n",
    "# Perform cross-validation for the LinearSVC model\n",
    "linear_svc_scores = cross_validate(linear_svc_model, X, y, scoring=scoring_metric, cv=5, return_train_score=True)\n",
    "linear_svc_train_accuracy = linear_svc_scores['train_score'].mean()\n",
    "linear_svc_validation_accuracy = linear_svc_scores['test_score'].mean()\n",
    "\n",
    "# Print the average training and validation accuracies for both models\n",
    "print(\"SVC - Training Accuracy:\", svc_train_accuracy)\n",
    "print(\"SVC - Validation Accuracy:\", svc_validation_accuracy)\n",
    "print(\"LinearSVC - Training Accuracy:\", linear_svc_train_accuracy)\n",
    "print(\"LinearSVC - Validation Accuracy:\", linear_svc_validation_accuracy)\n",
    "\n",
    "# Determine which model has the highest validation accuracy\n",
    "best_method_svm = 'SVC' if svc_validation_accuracy > linear_svc_validation_accuracy else 'LinearSVC'\n",
    "\n",
    "print(\"Method with the Highest Validation Accuracy (SVMs):\", best_method_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {},
   "source": [
    "*ANSWER HERE*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
